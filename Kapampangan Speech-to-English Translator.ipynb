{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e25ff3",
   "metadata": {},
   "source": [
    "# Kapampangan Speech-to-English Translation Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac381dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Requirements\n",
    "# - Trained Wav2Vec2 ASR model\n",
    "# - Trained MarianMT translation model\n",
    "# - Hugging Face Transformers, Torchaudio, PyTorch\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from transformers import MarianTokenizer, MarianMTModel\n",
    "\n",
    "# --- Configuration ---\n",
    "ASR_MODEL_DIR = \"./kapampangan_wav2vec2_model\"         # Path to fine-tuned Wav2Vec2 model\n",
    "MT_MODEL_DIR = \"./kapampangan_mt_model\"               # Path to fine-tuned MarianMT model\n",
    "\n",
    "# --- Load ASR Components ---\n",
    "asr_processor = Wav2Vec2Processor.from_pretrained(ASR_MODEL_DIR)\n",
    "if isinstance(asr_processor, tuple):\n",
    "    asr_processor = asr_processor[0]\n",
    "# Ensure asr_processor is the correct type\n",
    "assert hasattr(asr_processor, '__call__'), \"asr_processor is not callable\"\n",
    "asr_model = Wav2Vec2ForCTC.from_pretrained(ASR_MODEL_DIR)\n",
    "asr_model = asr_model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "asr_model.eval()\n",
    "\n",
    "# --- Load MarianMT Components ---\n",
    "mt_tokenizer = MarianTokenizer.from_pretrained(MT_MODEL_DIR)\n",
    "mt_model = MarianMTModel.from_pretrained(MT_MODEL_DIR)\n",
    "mt_model = mt_model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mt_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeabc22",
   "metadata": {},
   "source": [
    "# Function: Audio -> Kapampangan Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773036f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asr_transcribe(audio_path):\n",
    "    waveform, sr = torchaudio.load(audio_path)\n",
    "    if sr != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(sr, 16000)\n",
    "        waveform = resampler(waveform)\n",
    "    waveform = waveform.squeeze()\n",
    "    inputs = asr_processor(waveform, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = asr_model(**inputs.to(asr_model.device)).logits\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = asr_processor.batch_decode(pred_ids)[0]\n",
    "    print(f\"üîç Raw prediction IDs: {pred_ids}\")\n",
    "    print(f\"üìù Raw transcription output: {transcription}\")\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d28cda6",
   "metadata": {},
   "source": [
    "# Combined Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9986ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_translation(audio_path):\n",
    "    print(f\"üîä Processing audio: {audio_path}\")\n",
    "    kapampangan_text = asr_transcribe(audio_path)\n",
    "    print(f\"üìù Transcription: {kapampangan_text}\")\n",
    "    english_translation = kapampangan_translate(kapampangan_text)\n",
    "    print(f\"üåê Translation: {english_translation}\")\n",
    "    return english_translation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac1123",
   "metadata": {},
   "source": [
    "#  Tokenizer Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d779f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(asr_processor.tokenizer.get_vocab().keys())[:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909dc1a",
   "metadata": {},
   "source": [
    "# Example Inference from Audio File\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c29ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example_audio = \"data/validated_audio/cat03_entry001_spk013.wav\"\n",
    "speech_to_translation(example_audio)\n",
    "\n",
    "manual_kapampangan = \"Nanu ya ing kayang pamangan?\"\n",
    "print(\"üåê Translation Test:\", kapampangan_translate(manual_kapampangan))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

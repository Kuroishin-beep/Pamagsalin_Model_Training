{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0920e692",
   "metadata": {},
   "source": [
    "# === Kapampangan-to-English NLLB-200 Training Pipeline (with <kap> tag) ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbb73aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments\n",
    ")\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57188df0",
   "metadata": {},
   "source": [
    "# === 1. Config ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec6a97df",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"data/kapampangan_english.csv\"\n",
    "MODEL_NAME = \"facebook/nllb-200-distilled-600M\"\n",
    "MODEL_DIR = \"./kapampangan_mt_nllb\"\n",
    "\n",
    "SPECIAL_SRC_TOKEN = \"<kap>\"   # Custom Kapampangan language marker\n",
    "TGT_LANG = \"eng_Latn\"         # English (Latin script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215a3088",
   "metadata": {},
   "source": [
    "# === 2. Load CSV ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0206e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "df = df.rename(columns={\"kapampangan\": \"src_text\", \"english\": \"tgt_text\"})\n",
    "df = df.dropna(subset=[\"src_text\", \"tgt_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa01e85",
   "metadata": {},
   "source": [
    "# === 3. Convert to HF Dataset ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db28d226",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df[[\"src_text\", \"tgt_text\"]])\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb4569c",
   "metadata": {},
   "source": [
    "# === 4. Load Tokenizer & Model ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efd264c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)  # No src_lang yet\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Add <kap> as a special token\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': [SPECIAL_SRC_TOKEN]})\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Force English output\n",
    "model.config.forced_bos_token_id = tokenizer.convert_tokens_to_ids(TGT_LANG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a50c0a5",
   "metadata": {},
   "source": [
    "# === 5. Preprocess ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b26a7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb99a6b9da745d891c0a20941cf7016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/926 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a0723fc26d47beaf80dd3c04e078e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/232 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(examples):\n",
    "    # Prepend <kap> to source text\n",
    "    src_texts = [f\"{SPECIAL_SRC_TOKEN} {text}\" for text in examples[\"src_text\"]]\n",
    "\n",
    "    # Tokenize source\n",
    "    model_inputs = tokenizer(\n",
    "        src_texts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "    # Tokenize target\n",
    "    labels = tokenizer(\n",
    "        examples[\"tgt_text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    # Replace pad token IDs with -100\n",
    "    labels = [[(t if t != tokenizer.pad_token_id else -100) for t in label] for label in labels]\n",
    "    model_inputs[\"labels\"] = labels\n",
    "\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760f518c",
   "metadata": {},
   "source": [
    "# === 6. Training Args ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "574bfdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca83bb2cf8e4f7283a85b9dfb8ea4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "    # Replace -100 with pad_token_id so metric can handle it\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    accuracy = metric_acc.compute(predictions=predictions, references=labels)\n",
    "    return {\"accuracy\": accuracy[\"accuracy\"]}\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=MODEL_DIR,\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    eval_steps=500,       # evaluate every 500 steps\n",
    "    logging_steps=500,    # log every 500 steps\n",
    "    save_steps=500,       # save every 500 steps\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d853e4",
   "metadata": {},
   "source": [
    "# === 7. Trainer ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f79487ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angelica\\AppData\\Local\\Temp\\ipykernel_9580\\2430946255.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94068b3b",
   "metadata": {},
   "source": [
    "# === 8. Train ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27f2d1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3480' max='3480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3480/3480 9:13:39, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.179400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.254100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.072600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.027400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Angelica\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:3685: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'forced_bos_token_id': 256047}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3480, training_loss=0.22363907773604338, metrics={'train_runtime': 33227.4144, 'train_samples_per_second': 0.418, 'train_steps_per_second': 0.105, 'total_flos': 3762635365416960.0, 'train_loss': 0.22363907773604338, 'epoch': 15.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dd79ae",
   "metadata": {},
   "source": [
    "# === 9. Save ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c64989f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to: ./kapampangan_mt_nllb\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(MODEL_DIR)\n",
    "tokenizer.save_pretrained(MODEL_DIR)\n",
    "print(f\"✅ Model saved to: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55379746",
   "metadata": {},
   "source": [
    "# === 10. Translation Function ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3ccacd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_translate(texts, batch_size=8):\n",
    "    results = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        src_texts = [f\"{SPECIAL_SRC_TOKEN} {t}\" for t in texts[i:i+batch_size]]\n",
    "        inputs = tokenizer(src_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs)\n",
    "        results.extend(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8ea2d2",
   "metadata": {},
   "source": [
    "# === 11. Evaluate BLEU ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0d444b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating BLEU Score ---\n",
      " BLEU Score: {'bleu': 0.29751167185801497, 'precisions': [0.5785907859078591, 0.32395498392282956, 0.23122529644268774, 0.18076923076923077], 'brevity_penalty': 1.0, 'length_ratio': 1.021453287197232, 'translation_length': 1476, 'reference_length': 1445}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluating BLEU Score ---\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "test_df = dataset[\"test\"].to_pandas()\n",
    "preds = batch_translate(test_df[\"src_text\"].tolist())\n",
    "refs = [[x] for x in test_df[\"tgt_text\"].tolist()]\n",
    "\n",
    "bleu_score = bleu.compute(predictions=preds, references=refs)\n",
    "print(\" BLEU Score:\", bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83331cbf",
   "metadata": {},
   "source": [
    "# === 12. Manual Test ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41e8f013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Manual Test ---\n",
      "[1] Kapampangan: Ali ku balu\n",
      "    ➤ English: I don't know.\n",
      "[2] Kapampangan: Anya ka?\n",
      "    ➤ English: Are you hungry?\n",
      "[3] Kapampangan: Masanting ya ing panaun ngeni\n",
      "    ➤ English: It's a good-looking day now.\n",
      "[4] Kapampangan: E ku makanyan\n",
      "    ➤ English: I'm not that old.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Manual Test ---\")\n",
    "sample_texts = [\n",
    "    \"Ali ku balu\",\n",
    "    \"Anya ka?\",\n",
    "    \"Masanting ya ing panaun ngeni\",\n",
    "    \"E ku makanyan\",\n",
    "]\n",
    "\n",
    "for i, kap_text in enumerate(sample_texts):\n",
    "    translated = batch_translate([kap_text])[0]\n",
    "    print(f\"[{i+1}] Kapampangan: {kap_text}\")\n",
    "    print(f\"    ➤ English: {translated}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

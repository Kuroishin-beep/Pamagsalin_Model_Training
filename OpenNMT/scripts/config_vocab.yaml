## Data
save_data: runs/data_index
data:
  corpus_1:
    path_src: data/onmt/train.kap
    path_tgt: data/onmt/train.eng
  valid:
    path_src: data/onmt/valid.kap
    path_tgt: data/onmt/valid.eng

## Transforms - each transform should be listed separately
transforms: [filtertoolong, onmt_tokenize, sentencepiece]

## Transform configurations
# Filter Too Long configuration
src_seq_length: 256
tgt_seq_length: 256

# Onmt Tokenizer configuration  
onmt_tokenize:
  mode: space

# SentencePiece configuration
src_subword_model: data/sp/spm_shared.model
tgt_subword_model: data/sp/spm_shared.model
share_vocab: true

# Required vocabulary parameters
src_vocab: runs/vocab.src
tgt_vocab: runs/vocab.tgt